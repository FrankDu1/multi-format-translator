from flask import Flask, request, jsonify
from flask_cors import CORS
from paddleocr import PaddleOCR
import cv2
import numpy as np
import base64
import time
import logging
import os
import re
from datetime import datetime

# ========== GPUé…ç½® - é™åˆ¶æ˜¾å­˜ä½¿ç”¨ ==========
# è®¾ç½®PaddlePaddleæ˜¾å­˜ä½¿ç”¨ (1GB = 12.5% on 8GB GPU)
os.environ['FLAGS_fraction_of_gpu_memory_to_use'] = '0.125'  # é™åˆ¶1GB
os.environ['FLAGS_allocator_strategy'] = 'auto_growth'        # æŒ‰éœ€å¢žé•¿
os.environ['CUDA_VISIBLE_DEVICES'] = '0'                      # ä½¿ç”¨GPU 0

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# çŽ¯å¢ƒå˜é‡é…ç½®
OCR_HOST = os.getenv('OCR_HOST', '0.0.0.0')
OCR_PORT = int(os.getenv('OCR_PORT', '8899'))
ALLOWED_ORIGINS = os.getenv('ALLOWED_ORIGINS', '*')

app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": ALLOWED_ORIGINS}})

# åˆå§‹åŒ–OCRå¼•æ“Ž
logger.info("ðŸš€ åˆå§‹åŒ–PaddleOCR...")
try:
    ocr = PaddleOCR(
        use_doc_orientation_classify=False, 
        use_doc_unwarping=False, 
        use_textline_orientation=False,
        lang='ch',              # æ”¯æŒä¸­è‹±æ–‡
        # æ–°ç‰ˆæœ¬PaddleOCRé€šè¿‡çŽ¯å¢ƒå˜é‡æŽ§åˆ¶GPUå’Œæ˜¾å­˜ï¼Œä¸éœ€è¦è¿™äº›å‚æ•°
    )
    logger.info("âœ… PaddleOCRåˆå§‹åŒ–å®Œæˆ (GPUæ¨¡å¼, æ˜¾å­˜é™åˆ¶: 1GB)")
except Exception as e:
    logger.error(f"âŒ PaddleOCRåˆå§‹åŒ–å¤±è´¥: {e}")
    raise

def image_from_base64(base64_str):
    """ä»Žbase64å­—ç¬¦ä¸²è§£ç å›¾åƒï¼Œæ”¯æŒæ‰€æœ‰å¸¸è§æ ¼å¼ï¼ˆPNGã€JPGã€GIFã€WEBPç­‰ï¼‰"""
    try:
        # å¤„ç† data URL æ ¼å¼ (data:image/jpeg;base64,...)
        if base64_str.startswith('data:image'):
            logger.info("æ£€æµ‹åˆ°data URIæ ¼å¼ï¼Œç§»é™¤å‰ç¼€")
            if 'base64,' in base64_str:
                base64_str = base64_str.split('base64,')[1]
        
        # ç§»é™¤å¯èƒ½çš„ç©ºç™½å­—ç¬¦
        base64_str = base64_str.strip()
        
        # è§£ç base64
        image_bytes = base64.b64decode(base64_str)
        logger.info(f"Base64è§£ç æˆåŠŸï¼Œå­—èŠ‚é•¿åº¦: {len(image_bytes)}")
        
        # æ–¹æ³•1: å°è¯•ä½¿ç”¨OpenCVç›´æŽ¥è§£ç 
        image_array = np.frombuffer(image_bytes, np.uint8)
        image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)
        
        if image is not None:
            logger.info(f"âœ“ OpenCVè§£ç æˆåŠŸ: {image.shape}")
            return image
        
        # æ–¹æ³•2: ä½¿ç”¨PILå¤„ç†ï¼ˆæ”¯æŒGIFç­‰æ›´å¤šæ ¼å¼ï¼‰
        logger.info("OpenCVè§£ç å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨PIL...")
        try:
            from PIL import Image
            import io
            
            # ä½¿ç”¨PILæ‰“å¼€å›¾ç‰‡
            pil_image = Image.open(io.BytesIO(image_bytes))
            logger.info(f"PILæˆåŠŸæ‰“å¼€: æ¨¡å¼={pil_image.mode}, å°ºå¯¸={pil_image.size}, æ ¼å¼={pil_image.format}")
            
            # è½¬æ¢ä¸ºRGBæ¨¡å¼ï¼ˆå¤„ç†GIFã€RGBAã€Pæ¨¡å¼ç­‰ï¼‰
            if pil_image.mode in ('RGBA', 'LA'):
                # æœ‰é€æ˜Žé€šé“ï¼Œè½¬æ¢ä¸ºç™½è‰²èƒŒæ™¯
                logger.info(f"è½¬æ¢ {pil_image.mode} -> RGB (ç™½è‰²èƒŒæ™¯)")
                background = Image.new('RGB', pil_image.size, (255, 255, 255))
                background.paste(pil_image, mask=pil_image.split()[-1])
                pil_image = background
            elif pil_image.mode == 'P':
                # è°ƒè‰²æ¿æ¨¡å¼
                logger.info("è½¬æ¢ P -> RGB")
                pil_image = pil_image.convert('RGB')
            elif pil_image.mode != 'RGB':
                # å…¶ä»–æ¨¡å¼
                logger.info(f"è½¬æ¢ {pil_image.mode} -> RGB")
                pil_image = pil_image.convert('RGB')
            
            # è½¬æ¢ä¸ºOpenCVæ ¼å¼ (BGR)
            image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
            logger.info(f"âœ“ PILè½¬æ¢æˆåŠŸ: {image.shape}")
            return image
            
        except Exception as pil_error:
            logger.error(f"PILå¤„ç†å¤±è´¥: {pil_error}")
            raise ValueError(f"å›¾åƒè§£ç å¤±è´¥: OpenCVå’ŒPILéƒ½æ— æ³•è§£ç ")
        
    except base64.binascii.Error as e:
        logger.error(f"Base64è§£ç é”™è¯¯: {e}")
        raise ValueError(f"Base64æ ¼å¼é”™è¯¯: {str(e)}")
    except Exception as e:
        logger.error(f"å›¾åƒå¤„ç†é”™è¯¯: {e}", exc_info=True)
        raise ValueError(f"å›¾åƒå¤„ç†å¤±è´¥: {str(e)}")

def serialize_ocr_result(result):
    """å°†OCRç»“æžœåºåˆ—åŒ–ä¸ºå¯JSONåŒ–çš„æ ¼å¼"""
    serialized_results = []
    
    try:
        for i, res in enumerate(result if result else []):
            try:
                # PaddleOCRç»“æžœé€šå¸¸æ˜¯ä¸€ä¸ªåŒ…å«æ£€æµ‹å’Œè¯†åˆ«ä¿¡æ¯çš„å¯¹è±¡
                if hasattr(res, 'json'):
                    # ä½¿ç”¨PaddleOCRæä¾›çš„jsonå±žæ€§
                    res_dict = res.json
                elif isinstance(res, dict):
                    # å·²ç»æ˜¯å­—å…¸æ ¼å¼
                    res_dict = res
                else:
                    # æ‰‹åŠ¨æå–å±žæ€§
                    res_dict = {}
                    
                    # å°è¯•èŽ·å–å¸¸è§å±žæ€§
                    if hasattr(res, '__dict__'):
                        for key, value in res.__dict__.items():
                            try:
                                if hasattr(value, 'tolist'):  # numpyæ•°ç»„
                                    res_dict[key] = value.tolist()
                                elif isinstance(value, (list, tuple)):
                                    # é€’å½’å¤„ç†åˆ—è¡¨ä¸­çš„numpyæ•°ç»„
                                    res_dict[key] = [
                                        v.tolist() if hasattr(v, 'tolist') else v 
                                        for v in value
                                    ]
                                elif isinstance(value, (str, int, float, bool, type(None))):
                                    res_dict[key] = value
                                else:
                                    res_dict[key] = str(value)
                            except Exception as e:
                                logger.warning(f"åºåˆ—åŒ–å±žæ€§ {key} å¤±è´¥: {e}")
                                res_dict[key] = str(value)
                
                serialized_results.append(res_dict)
                
            except Exception as e:
                logger.error(f"åºåˆ—åŒ–ç¬¬ {i} ä¸ªç»“æžœå¤±è´¥: {e}")
                # æ·»åŠ é”™è¯¯ä¿¡æ¯ä½†ç»§ç»­å¤„ç†
                serialized_results.append({
                    'error': f'åºåˆ—åŒ–å¤±è´¥: {str(e)}',
                    'index': i
                })
                
    except Exception as e:
        logger.error(f"åºåˆ—åŒ–OCRç»“æžœæ•´ä½“å¤±è´¥: {e}")
        return [{
            'error': f'åºåˆ—åŒ–å¤±è´¥: {str(e)}',
            'result_type': str(type(result)),
            'result_length': len(result) if result else 0
        }]
    
    return serialized_results

def detect_text_language(text):
    """
    æ£€æµ‹æ–‡æœ¬è¯­è¨€ï¼ˆå¢žå¼ºç‰ˆï¼‰- æ”¯æŒå¾·è¯­è¯æ±‡æ£€æµ‹
    """
    text_lower = text.lower().strip()
    
    if not text_lower:
        return 'unknown'
    
    # ä¸­æ–‡å­—ç¬¦èŒƒå›´
    chinese_pattern = re.compile(r'[\u4e00-\u9fff]')
    # æ—¥æ–‡å‡å
    japanese_pattern = re.compile(r'[\u3040-\u309f\u30a0-\u30ff]')
    # éŸ©æ–‡
    korean_pattern = re.compile(r'[\uac00-\ud7af]')
    # å¾·è¯­ç‰¹æ®Šå­—ç¬¦
    german_special_pattern = re.compile(r'[Ã¤Ã¶Ã¼Ã„Ã–ÃœÃŸ]')
    # è‹±æ–‡å­—æ¯
    english_pattern = re.compile(r'[a-zA-Z]')
    
    # å¸¸è§å¾·è¯­è¯æ±‡ï¼ˆä¸å«ç‰¹æ®Šå­—ç¬¦ï¼‰
    common_german_words = {
        'der', 'die', 'das', 'und', 'ist', 'du', 'ich', 'wir', 'sie', 
        'hallo', 'guten', 'tag', 'morgen', 'abend', 'nacht',
        'bitte', 'danke', 'ja', 'nein', 'nicht', 'oder', 'aber',
        'von', 'zu', 'mit', 'fÃ¼r', 'auf', 'aus', 'ein', 'eine',
        'bin', 'bist', 'sind', 'sein', 'haben', 'hat', 'hast',
        'was', 'wer', 'wie', 'wo', 'warum', 'wann'
    }
    
    # å­—ç¬¦ç»Ÿè®¡
    chinese_count = len(chinese_pattern.findall(text))
    japanese_count = len(japanese_pattern.findall(text))
    korean_count = len(korean_pattern.findall(text))
    german_special_count = len(german_special_pattern.findall(text))
    english_count = len(english_pattern.findall(text))
    
    total_chars = len(text_lower)
    
    # ðŸ”¥ å¾·è¯­è¯æ±‡æ£€æµ‹
    german_word_count = 0
    words = re.findall(r'\b\w+\b', text_lower)
    for word in words:
        if word in common_german_words:
            german_word_count += 1
    
    german_word_ratio = german_word_count / len(words) if words else 0
    
    # è®¡ç®—å„è¯­è¨€å æ¯”
    chinese_ratio = chinese_count / total_chars
    japanese_ratio = japanese_count / total_chars
    korean_ratio = korean_count / total_chars
    english_ratio = english_count / total_chars
    
    # åˆ¤æ–­é€»è¾‘
    if chinese_ratio >= 0.3:
        return 'zh'
    elif japanese_ratio >= 0.3:
        return 'ja'
    elif korean_ratio >= 0.3:
        return 'ko'
    elif german_special_count > 0:
        return 'de'
    elif german_word_ratio >= 0.3:  # 30%çš„è¯æ±‡æ˜¯å¾·è¯­å¸¸ç”¨è¯
        return 'de'
    elif english_ratio >= 0.5:  # æœ‰è‹±æ–‡å­—æ¯ä¸”å æ¯”é«˜
        return 'en'
    else:
        return 'unknown'
    

def filter_ocr_by_language_v2(ocr_results, target_lang='zh'):
    """
    è¿‡æ»¤å·²åºåˆ—åŒ–çš„ OCR ç»“æžœ
    """
    if not ocr_results:
        logger.warning("âš ï¸  OCRç»“æžœä¸ºç©º")
        return []
    
    logger.info(f"ðŸ“Š å¼€å§‹è¿‡æ»¤ï¼Œè¾“å…¥ç»“æžœæ•°é‡: {len(ocr_results)}")
    
    filtered_results = []
    total_count = 0
    filtered_count = 0
    lang_stats = {}
    
    try:
        for idx, res in enumerate(ocr_results):
            logger.debug(f"å¤„ç†ç¬¬ {idx+1} ä¸ªç»“æžœï¼Œç±»åž‹: {type(res)}")
            
            if not isinstance(res, dict):
                logger.warning(f"âš ï¸  ç»“æžœ {idx+1} ä¸æ˜¯å­—å…¸: {type(res)}")
                continue
            
            if 'res' not in res:
                logger.warning(f"âš ï¸  ç»“æžœ {idx+1} æ²¡æœ‰ 'res' é”®ï¼Œé”®åˆ—è¡¨: {list(res.keys())}")
                continue
            
            rec_res = res['res']
            
            if 'rec_texts' not in rec_res:
                logger.warning(f"âš ï¸  ç»“æžœ {idx+1} çš„ 'res' æ²¡æœ‰ 'rec_texts' é”®ï¼Œé”®åˆ—è¡¨: {list(rec_res.keys())}")
                continue
            
            rec_texts = rec_res['rec_texts']
            rec_scores = rec_res.get('rec_scores', [])
            
            # ðŸ”¥ å°è¯•å¤šä¸ªå¯èƒ½çš„ box é”®
            boxes = (rec_res.get('dt_polys') or 
                    rec_res.get('rec_polys') or 
                    rec_res.get('rec_boxes') or [])
            
            logger.info(f"ðŸ“ ç»“æžœ {idx+1}: å…± {len(rec_texts)} ä¸ªæ–‡æœ¬")
            
            filtered_texts = []
            filtered_scores = []
            filtered_boxes = []
            
            for i, text in enumerate(rec_texts):
                total_count += 1
                
                if not text or not text.strip():
                    logger.debug(f"  è·³è¿‡ç©ºæ–‡æœ¬ {i+1}")
                    continue
                
                # æ£€æµ‹è¯­è¨€
                detected_lang = detect_text_language(text)
                
                logger.info(f"  [{i+1}] '{text}' -> {detected_lang}")
                
                # ç»Ÿè®¡
                if detected_lang not in lang_stats:
                    lang_stats[detected_lang] = {'count': 0, 'texts': []}
                lang_stats[detected_lang]['count'] += 1
                if len(lang_stats[detected_lang]['texts']) < 3:
                    lang_stats[detected_lang]['texts'].append(text)
                
                # åˆ¤æ–­æ˜¯å¦ä¿ç•™
                if detected_lang == target_lang:
                    filtered_texts.append(text)
                    filtered_scores.append(rec_scores[i] if i < len(rec_scores) else 0.0)
                    if i < len(boxes):
                        filtered_boxes.append(boxes[i])
                    filtered_count += 1
                    logger.info(f"      âœ“ ä¿ç•™")
                else:
                    logger.info(f"      âœ— è¿‡æ»¤ (éœ€è¦ {target_lang})")
            
            # å¦‚æžœæœ‰ä¿ç•™çš„æ–‡æœ¬ï¼Œæ·»åŠ åˆ°ç»“æžœ
            if filtered_texts:
                logger.info(f"âœ“ ç»“æžœ {idx+1}: ä¿ç•™ {len(filtered_texts)} ä¸ªæ–‡æœ¬")
                
                # ðŸ”¥ ä¿æŒåŽŸå§‹ç»“æž„
                filtered_res = {
                    'res': {
                        'rec_texts': filtered_texts,
                        'rec_scores': filtered_scores
                    }
                }
                
                # æ·»åŠ  boxesï¼ˆå¦‚æžœæœ‰ï¼‰
                if filtered_boxes:
                    if 'dt_polys' in rec_res:
                        filtered_res['res']['dt_polys'] = filtered_boxes
                    elif 'rec_polys' in rec_res:
                        filtered_res['res']['rec_polys'] = filtered_boxes
                    elif 'rec_boxes' in rec_res:
                        filtered_res['res']['rec_boxes'] = filtered_boxes
                
                # ðŸ”¥ ä¿ç•™å…¶ä»–é‡è¦å­—æ®µ
                for key in rec_res:
                    if key not in ['rec_texts', 'rec_scores', 'dt_polys', 'rec_polys', 'rec_boxes']:
                        filtered_res['res'][key] = rec_res[key]
                
                filtered_results.append(filtered_res)
            else:
                logger.info(f"âœ— ç»“æžœ {idx+1}: æ²¡æœ‰ä¿ç•™ä»»ä½•æ–‡æœ¬")
        
        # æ‰“å°ç»Ÿè®¡
        logger.info(f"\nðŸ” è¯­è¨€æ£€æµ‹ç»Ÿè®¡:")
        for lang, stats in sorted(lang_stats.items(), key=lambda x: -x[1]['count']):
            examples = ', '.join(f"'{t}'" for t in stats['texts'][:3])
            logger.info(f"   {lang.upper()}: {stats['count']} ä¸ª (ç¤ºä¾‹: {examples})")
        
        logger.info(f"\nðŸ” è¿‡æ»¤ç»“æžœ: {total_count} ä¸ªæ–‡æœ¬ â†’ {filtered_count} ä¸ª {target_lang.upper()} æ–‡æœ¬")
        logger.info(f"ðŸ“Š è¾“å‡ºç»“æžœæ•°é‡: {len(filtered_results)}")
        
    except Exception as e:
        logger.error(f"âŒ è¯­è¨€è¿‡æ»¤å¤±è´¥: {e}", exc_info=True)
        return ocr_results  # å¤±è´¥æ—¶è¿”å›žåŽŸå§‹ç»“æžœ
    
    return filtered_results


@app.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        'status': 'healthy',
        'ocr_available': True,
        'timestamp': datetime.now().isoformat(),
        'version': '2.0.2',
        'gpu_memory_limit': '1GB'
    })

@app.route('/ocr', methods=['POST'])
def ocr_api():
    """OCRè¯†åˆ«æŽ¥å£ - è¿”å›žåŽŸå§‹OCRç»“æžœ"""
    start_time = time.time()
    request_id = f"req_{int(start_time * 1000)}"
    
    logger.info(f"[{request_id}] æ”¶åˆ°OCRè¯†åˆ«è¯·æ±‚")
    
    try:
        if not request.is_json:
            return jsonify({
                'success': False,
                'error': 'è¯·æ±‚Content-Typeå¿…é¡»æ˜¯application/json',
                'request_id': request_id
            }), 400
        
        data = request.get_json()
        if not data:
            return jsonify({
                'success': False,
                'error': 'è¯·æ±‚æ•°æ®ä¸ºç©º',
                'request_id': request_id
            }), 400
        
        # ðŸ”¥ ä»Žè¯·æ±‚ä¸­è¯»å–å‚æ•°
        source_lang = data.get('source_lang', None)
        filter_enabled = data.get('filter_by_language', False)
        
        logger.info(f"[{request_id}] å‚æ•°: source_lang={source_lang}, filter_enabled={filter_enabled}")
        
        # èŽ·å–å›¾åƒ
        image = None
        if 'url' in data and data['url']:
            import requests
            logger.info(f"[{request_id}] ä»ŽURLåŠ è½½å›¾åƒ: {data['url']}")
            response = requests.get(data['url'], timeout=30)
            response.raise_for_status()
            image_array = np.frombuffer(response.content, np.uint8)
            image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)
            if image is None:
                raise ValueError("URLå›¾åƒè§£ç å¤±è´¥")
        else:
            image_data = None
            for key in ['image', 'image_base64', 'base64', 'img']:
                if key in data and data[key]:
                    image_data = data[key]
                    logger.info(f"[request_id] ä½¿ç”¨å‚æ•°: {key}")
                    break
            
            if not image_data:
                return jsonify({
                    'success': False,
                    'error': 'è¯·æä¾›æœ‰æ•ˆçš„image_base64æˆ–urlå‚æ•°',
                    'request_id': request_id,
                    'available_keys': list(data.keys())
                }), 400
            
            image = image_from_base64(image_data)
        
        logger.info(f"[{request_id}] å›¾åƒå°ºå¯¸: {image.shape}")
        
        # OCRè¯†åˆ«
        logger.info(f"[{request_id}] å¼€å§‹OCRè¯†åˆ«...")
        ocr_start_time = time.time()
        
        raw_ocr_result = ocr.predict(image)
        
        ocr_time = time.time() - ocr_start_time
        logger.info(f"[{request_id}] OCRè¯†åˆ«å®Œæˆï¼Œè€—æ—¶: {ocr_time:.3f}ç§’")
        
        # ðŸ”¥ å…ˆåºåˆ—åŒ–ï¼ˆè½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼‰
        serialized_result = serialize_ocr_result(raw_ocr_result)
        
        # ðŸ”¥ ç„¶åŽåœ¨åºåˆ—åŒ–åŽçš„ç»“æžœä¸Šè¿‡æ»¤
        filtered = False
        if source_lang and filter_enabled:
            logger.info(f"[{request_id}] ðŸ” å¼€å§‹è¯­è¨€è¿‡æ»¤ (ç›®æ ‡: {source_lang})...")
            filter_start_time = time.time()
            
            # ðŸ”¥ åœ¨åºåˆ—åŒ–åŽçš„ç»“æžœä¸Šè¿‡æ»¤
            serialized_result = filter_ocr_by_language_v2(
                serialized_result,  # ä¼ å…¥åºåˆ—åŒ–åŽçš„ç»“æžœ
                target_lang=source_lang
            )
            
            filter_time = time.time() - filter_start_time
            filtered = True
            logger.info(f"[{request_id}] âœ“ è¯­è¨€è¿‡æ»¤å®Œæˆï¼Œè€—æ—¶: {filter_time:.3f}ç§’")
        else:
            logger.info(f"[{request_id}] âŠ— è·³è¿‡è¯­è¨€è¿‡æ»¤")
        
        processing_time = time.time() - start_time
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_texts = 0
        try:
            for res_dict in serialized_result:
                if isinstance(res_dict, dict) and 'res' in res_dict:
                    rec_texts = res_dict['res'].get('rec_texts', [])
                    total_texts += len(rec_texts)
        except:
            pass
        
        logger.info(f"[{request_id}] å¤„ç†å®Œæˆï¼Œè¯†åˆ«åˆ° {total_texts} ä¸ªæ–‡æœ¬ï¼Œæ€»è€—æ—¶: {processing_time:.3f}ç§’")
        
        # è¿”å›žç»“æžœ
        return jsonify({
            'success': True,
            'result': serialized_result,
            'request_id': request_id,
            'processing_time': round(processing_time, 3),
            'ocr_time': round(ocr_time, 3),
            'total_texts': total_texts,
            'source_lang': source_lang,
            'filtered': filtered
        })
        
    except Exception as e:
        error_time = time.time() - start_time
        logger.error(f"[{request_id}] å¤„ç†å¤±è´¥: {str(e)}", exc_info=True)
        
        return jsonify({
            'success': False,
            'error': str(e),
            'error_type': type(e).__name__,
            'request_id': request_id,
            'processing_time': round(error_time, 3)
        }), 500

@app.route('/ocr/parsed', methods=['POST'])
def ocr_parsed_api():
    """OCRè¯†åˆ«æŽ¥å£ - è¿”å›žè§£æžç»“æžœ"""
    # è¿™ä¸ªæŽ¥å£ä¿æŒåŽŸæ ·ï¼Œä¸ä½¿ç”¨
    pass

if __name__ == '__main__':
    logger.info(f"âœ… æœåŠ¡å¯åŠ¨å®Œæˆï¼Œç›‘å¬åœ°å€: {OCR_HOST}:{OCR_PORT}")
    logger.info("ðŸ“‹ å¯ç”¨æŽ¥å£:")
    logger.info("  - GET  /health     : å¥åº·æ£€æŸ¥")
    logger.info("  - POST /ocr        : OCRè¯†åˆ«ï¼ˆè¿”å›žåŽŸå§‹ç»“æžœï¼‰")
    logger.info("  - POST /ocr/parsed : OCRè¯†åˆ«ï¼ˆè¿”å›žè§£æžç»“æžœï¼Œå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰")
    logger.info("ðŸ’¾ GPUæ˜¾å­˜é™åˆ¶: 1GB (é€šè¿‡çŽ¯å¢ƒå˜é‡æŽ§åˆ¶)")
    app.run(host=OCR_HOST, port=OCR_PORT, debug=False, threaded=True)