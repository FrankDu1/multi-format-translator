import os
import fitz  # PyMuPDF
import re
from typing import List, Dict, Tuple
from logger_config import app_logger

UPLOAD_DIR = os.path.join(os.path.dirname(__file__), '..', 'uploads')

def translate_pdf_file(pdf_file_path, src_lang='auto', tgt_lang='zh', enable_summary=False):
    try:
        from services.nllb_translator_pipeline import get_translator
        translator = get_translator()
        summary_result = None

        app_logger.info(f"ğŸš€ å¼€å§‹PDFç¿»è¯‘: {pdf_file_path}")
        
        # æ‰“å¼€PDF
        doc = fitz.open(pdf_file_path)
        
        # ã€å…³é”®ä¼˜åŒ–1ã€‘æ”¹è¿›æ–‡æœ¬æå–ï¼šæŒ‰è§†è§‰è¡Œæå–ï¼Œé¿å…ç¢ç‰‡åŒ–
        all_texts = []
        text_positions = []
        
        app_logger.info("ğŸ“ æå–PDFæ–‡æœ¬ï¼ˆæŒ‰è§†è§‰è¡Œï¼‰...")
        
        for page_num in range(len(doc)):
            page = doc[page_num]
            
            # è·å–é¡µé¢æ‰€æœ‰å•è¯
            words = page.get_text("words")
            if not words:
                continue
            
            # æŒ‰Yåæ ‡åˆ†ç»„å½¢æˆè§†è§‰è¡Œ
            from collections import defaultdict
            lines_dict = defaultdict(list)
            
            for word_info in words:
                x0, y0, x1, y1, text, _, _, _ = word_info
                if not text.strip():
                    continue
                
                # ä½¿ç”¨ç²¾ç¡®çš„Yåæ ‡åˆ†ç»„ï¼ˆåŒä¸€è¡Œçš„æ–‡æœ¬ï¼‰
                y_key = round(y0, 1)  # å››èˆäº”å…¥åˆ°å°æ•°ç‚¹å1ä½
                lines_dict[y_key].append({
                    'x0': x0,
                    'text': text,
                    'rect': fitz.Rect(x0, y0, x1, y1)
                })
            
            # å¤„ç†æ¯ä¸€è¡Œ
            for y_key in sorted(lines_dict.keys()):
                line_items = lines_dict[y_key]
                
                # æŒ‰Xåæ ‡æ’åºï¼ˆä»å·¦åˆ°å³ï¼‰
                line_items.sort(key=lambda item: item['x0'])
                
                # ç»„åˆè¡Œæ–‡æœ¬
                line_text = ' '.join(item['text'] for item in line_items)
                
                # è®¡ç®—è¡Œçš„æ•´ä½“è¾¹ç•Œæ¡†
                line_rect = None
                for item in line_items:
                    if line_rect is None:
                        line_rect = item['rect']
                    else:
                        line_rect = line_rect.include_rect(item['rect'])
                
                if line_text.strip() and line_rect:
                    all_texts.append(line_text.strip())
                    text_positions.append({
                        'page_num': page_num,
                        'rect': line_rect,
                        'font_size': max(8, line_rect.height),
                        'original_text': line_text.strip()
                    })
        
        app_logger.info(f"âœ… æå–å®Œæˆ: {len(all_texts)} ä¸ªæ–‡æœ¬è¡Œ")
        
        # æ˜¾ç¤ºå‰å‡ è¡Œç”¨äºè°ƒè¯•
        for i, text in enumerate(all_texts[:5]):
            pos = text_positions[i]
            app_logger.debug(f"  è¡Œ{i+1}: '{text}' (é¡µ{pos['page_num']+1}, Y={pos['rect'].y0})")
        
        # è¯­è¨€æ£€æµ‹ï¼ˆä¿æŒä¸å˜ï¼‰
        if src_lang == 'auto':
            sample = ' '.join(all_texts[:3])
            chinese_chars = sum(1 for c in sample if '\u4e00' <= c <= '\u9fff')
            english_chars = sum(1 for c in sample if 'a' <= c.lower() <= 'z')
            src_lang = 'zh' if chinese_chars > english_chars else 'en'
            app_logger.info(f"ğŸ” æ£€æµ‹åˆ°æºè¯­è¨€: {src_lang}")
        
        # ã€å…³é”®ä¼˜åŒ–2ã€‘æ‰¹é‡ç¿»è¯‘
        app_logger.info(f"ğŸ”¤ æ‰¹é‡ç¿»è¯‘ ({src_lang} -> {tgt_lang})...")
        translated_texts = translator.translate_batch(
            all_texts, 
            src_lang=src_lang, 
            tgt_lang=tgt_lang,
            batch_size=6  # é€‚å½“å‡å°æ‰¹æ¬¡å¤§å°
        )
        
        # ç¡®ä¿ç»“æœæ•°é‡åŒ¹é…
        if len(translated_texts) != len(all_texts):
            app_logger.warning(f"âš ï¸ ç»“æœæ•°é‡ä¸åŒ¹é…ï¼Œè¿›è¡Œè°ƒæ•´")
            if len(translated_texts) < len(all_texts):
                translated_texts.extend([''] * (len(all_texts) - len(translated_texts)))
            else:
                translated_texts = translated_texts[:len(all_texts)]
        
        # ã€å…³é”®ä¼˜åŒ–3ã€‘æ”¹è¿›çš„PDFå†™å›é€»è¾‘
        app_logger.info("ğŸ“„ ç”Ÿæˆç¿»è¯‘åçš„PDF...")
        
        # åˆ›å»ºæ–°æ–‡æ¡£ï¼Œè€Œä¸æ˜¯ä¿®æ”¹åŸæ–‡æ¡£
        new_doc = fitz.open()
        
        for page_num in range(len(doc)):
            original_page = doc[page_num]
            
            # åˆ›å»ºæ–°é¡µé¢ï¼ˆä¿æŒåŸå°ºå¯¸ï¼‰
            new_page = new_doc.new_page(
                width=original_page.rect.width,
                height=original_page.rect.height
            )
            
            # æ”¶é›†è¿™ä¸€é¡µçš„æ‰€æœ‰ç¿»è¯‘
            page_items = []
            for i, pos in enumerate(text_positions):
                if pos['page_num'] == page_num and i < len(translated_texts):
                    if translated_texts[i].strip():  # åªå¤„ç†éç©ºç¿»è¯‘
                        page_items.append((pos, translated_texts[i]))
            
            if not page_items:
                continue
            
            # æŒ‰Yåæ ‡æ’åºï¼ˆä»ä¸Šåˆ°ä¸‹ï¼‰
            page_items.sort(key=lambda x: x[0]['rect'].y0)
            
            # å†™å…¥ç¿»è¯‘æ–‡æœ¬
            for pos_info, translated in page_items:
                rect = pos_info['rect']
                font_size = pos_info['font_size']
                
                try:
                    new_page.insert_text(
                        (rect.x0, rect.y0 + font_size * 0.8),
                        translated,
                        fontsize=min(font_size, 14),  # é™åˆ¶å­—ä½“å¤§å°
                        color=(0, 0, 0),
                        fontname="china-s"
                    )
                except:
                    # å›é€€æ–¹æ¡ˆ
                    try:
                        new_page.insert_text(
                            (rect.x0, rect.y0 + font_size * 0.8),
                            translated[:100],  # æˆªæ–­é•¿æ–‡æœ¬
                            fontsize=min(font_size, 14),
                            color=(0, 0, 0)
                        )
                    except Exception as e:
                        app_logger.warning(f"âš ï¸ æ–‡æœ¬æ’å…¥å¤±è´¥: {e}")
        
        # ä¿å­˜æ–‡ä»¶
        out_filename = f"translated_{os.path.basename(pdf_file_path)}"
        out_path = os.path.join(UPLOAD_DIR, out_filename)
        os.makedirs(os.path.dirname(out_path), exist_ok=True)
        
        new_doc.save(out_path)
        new_doc.close()
        doc.close()
        
        app_logger.info(f"âœ… PDFä¿å­˜æˆåŠŸ: {out_path}")
        
        # AIæ€»ç»“ï¼ˆä¿æŒä¸å˜ï¼‰
        if enable_summary:
            try:
                combined = '\n'.join(translated_texts[:20])
                if combined.strip():
                    app_logger.info("ğŸ§  ç”ŸæˆAIæ€»ç»“...")
                    from config import AI_PROVIDER
                    if AI_PROVIDER == 'qwen':
                        from services.qwen_service import qwen_service as ai_service
                    else:
                        from services.ollama_service import ollama_service as ai_service
                    
                    summary_result = ai_service.generate_summary(
                        text=combined,
                        target_language=tgt_lang
                    )
            except Exception as e:
                app_logger.error(f"âŒ AIæ€»ç»“å¼‚å¸¸: {e}")
        
        app_logger.info(f"ğŸ‰ PDFç¿»è¯‘å®Œæˆ")
        return out_path, summary_result
        
    except Exception as e:
        app_logger.error(f"âŒ PDFç¿»è¯‘å¤±è´¥: {e}")
        import traceback
        app_logger.error(traceback.format_exc())
        raise


def extract_pdf_debug_info(pdf_file_path):
    """
    è°ƒè¯•å‡½æ•°ï¼šæå–PDFç»“æ„ä¿¡æ¯
    """
    try:
        doc = fitz.open(pdf_file_path)
        app_logger.info("ğŸ” PDFè°ƒè¯•ä¿¡æ¯:")
        
        for page_num in range(min(2, len(doc))):  # åªåˆ†æå‰2é¡µ
            page = doc[page_num]
            app_logger.info(f"\nğŸ“„ é¡µé¢ {page_num + 1}:")
            
            # åŸå§‹æ–‡æœ¬
            raw_text = page.get_text()
            app_logger.info(f"  åŸå§‹æ–‡æœ¬é•¿åº¦: {len(raw_text)}å­—ç¬¦")
            if raw_text:
                app_logger.info(f"  å‰200å­—ç¬¦: {raw_text[:200]}")
            
            # æŒ‰å•è¯æå–
            words = page.get_text("words")
            app_logger.info(f"  å•è¯æ•°é‡: {len(words)}")
            
            # æŒ‰å­—å…¸æå–
            blocks = page.get_text("dict")["blocks"]
            text_blocks = [b for b in blocks if b["type"] == 0]
            app_logger.info(f"  æ–‡æœ¬å—æ•°é‡: {len(text_blocks)}")
            
            # æ˜¾ç¤ºå‰3ä¸ªæ–‡æœ¬å—çš„è¯¦ç»†ç»“æ„
            for i, block in enumerate(text_blocks[:3]):
                app_logger.info(f"\n  æ–‡æœ¬å— {i+1}:")
                for j, line in enumerate(block["lines"][:3]):  # åªæ˜¾ç¤ºå‰3è¡Œ
                    line_text = ""
                    for span in line["spans"]:
                        line_text += span["text"] + " "
                    app_logger.info(f"    è¡Œ{j+1}: '{line_text.strip()}'")
        
        doc.close()
        
    except Exception as e:
        app_logger.error(f"âŒ PDFè°ƒè¯•å¤±è´¥: {e}")

