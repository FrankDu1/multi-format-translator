"""
æœ¬åœ°ç¿»è¯‘æœåŠ¡ - ä½¿ç”¨ Hugging Face MarianMT æ¨¡å‹
æ”¯æŒç¦»çº¿ç¿»è¯‘ï¼Œæ— éœ€å¤–éƒ¨API
"""

import os
# Compatibility shim: ensure torch.utils._pytree has register_pytree_node if possible
from services.torch_compat import *  # noqa: F401,F403
from transformers import MarianMTModel, MarianTokenizer
import torch
from typing import List, Optional
import logging

# é…ç½®å›½å†…é•œåƒæºï¼ˆé€‚ç”¨äºä¸­å›½å¤§é™†ï¼‰
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

# é…ç½®æ—¥å¿— - åªæ˜¾ç¤ºå…³é”®ä¿¡æ¯
logging.basicConfig(
    level=logging.INFO,
    format='%(message)s'  # ç®€åŒ–æ ¼å¼ï¼Œä¸æ˜¾ç¤ºæ¨¡å—å
)
logger = logging.getLogger(__name__)

# æŠ‘åˆ¶ transformers çš„è¯¦ç»†æ—¥å¿—
logging.getLogger("transformers").setLevel(logging.WARNING)
logging.getLogger("transformers.modeling_utils").setLevel(logging.ERROR)


class LocalTranslator:
    """æœ¬åœ°ç¿»è¯‘å™¨ç±»"""
    
    def __init__(self):
        self.models = {}
        self.tokenizers = {}
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"âœ“ ç¿»è¯‘å™¨åˆå§‹åŒ–å®Œæˆ (è®¾å¤‡: {self.device.upper()})")
        
        # é¢„å®šä¹‰çš„æ¨¡å‹æ˜ å°„
        self.model_map = {
            ("zh", "en"): "Helsinki-NLP/opus-mt-zh-en",
            ("en", "zh"): "Helsinki-NLP/opus-mt-en-zh",
            # å¯ä»¥æ·»åŠ æ›´å¤šè¯­è¨€å¯¹
        }
    
    def load_model(self, source_lang: str, target_lang: str) -> bool:
        """
        åŠ è½½æŒ‡å®šè¯­è¨€å¯¹çš„ç¿»è¯‘æ¨¡å‹
        
        Args:
            source_lang: æºè¯­è¨€ä»£ç  (å¦‚ 'zh', 'en')
            target_lang: ç›®æ ‡è¯­è¨€ä»£ç  (å¦‚ 'zh', 'en')
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸåŠ è½½
        """
        lang_pair = (source_lang, target_lang)
        
        # å¦‚æœå·²ç»åŠ è½½ï¼Œç›´æ¥è¿”å›
        if lang_pair in self.models:
            logger.info(f"æ¨¡å‹å·²ç¼“å­˜ï¼Œç›´æ¥ä½¿ç”¨: {source_lang} -> {target_lang}")
            return True
        
        # è·å–æ¨¡å‹åç§°
        model_name = self.model_map.get(lang_pair)
        if not model_name:
            logger.error(f"ä¸æ”¯æŒçš„è¯­è¨€å¯¹: {source_lang} -> {target_lang}")
            return False
        
        try:
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½
            from pathlib import Path
            cache_dir = Path.home() / ".cache" / "huggingface" / "hub"
            model_cache = cache_dir / f"models--{model_name.replace('/', '--')}"
            
            if not model_cache.exists():
                print(f"\nâ³ é¦–æ¬¡è¿è¡Œï¼Œæ­£åœ¨ä¸‹è½½æ¨¡å‹...")
                print(f"ğŸ“¦ æ¨¡å‹: {model_name}")
                print(f"ğŸ“¦ å¤§å°: çº¦300MB")
                print(f"ğŸ’¾ ç¼“å­˜: {model_cache}")
                print(f"âš ï¸  è¯·å‹¿ä¸­æ–­ä¸‹è½½...\n")
                is_cached = False
            else:
                print(f"âœ“ æ¨¡å‹å·²ç¼“å­˜ï¼Œæ­£åœ¨åŠ è½½...")
                is_cached = True
            
            # åŠ è½½tokenizerå’Œæ¨¡å‹ï¼ˆæŠ‘åˆ¶è¯¦ç»†æ—¥å¿—ï¼‰
            print(f"  [1/3] åŠ è½½ Tokenizer...", end='', flush=True)
            import warnings
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                tokenizer = MarianTokenizer.from_pretrained(
                    model_name,
                    local_files_only=is_cached
                )
            print(" âœ“")
            
            print(f"  [2/3] åŠ è½½ç¿»è¯‘æ¨¡å‹...", end='', flush=True)
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                model = MarianMTModel.from_pretrained(
                    model_name,
                    local_files_only=is_cached
                )
            print(" âœ“")
            
            print(f"  [3/3] å‡†å¤‡æ¨ç†å¼•æ“...", end='', flush=True)
            model.to(self.device)
            model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            print(" âœ“")
            
            # ç¼“å­˜æ¨¡å‹
            self.tokenizers[lang_pair] = tokenizer
            self.models[lang_pair] = model
            
            print(f"âœ… æ¨¡å‹å°±ç»ªï¼({source_lang} â†’ {target_lang})\n")
            return True
            
        except Exception as e:
            print(f"\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}\n")
            print(f"å¯èƒ½çš„åŸå› :")
            print(f"  1. ç½‘ç»œè¿æ¥é—®é¢˜ï¼ˆé¦–æ¬¡éœ€è¦ä¸‹è½½æ¨¡å‹ï¼‰")
            print(f"  2. ç£ç›˜ç©ºé—´ä¸è¶³ï¼ˆéœ€è¦è‡³å°‘1GBï¼‰")
            print(f"  3. æƒé™é—®é¢˜ï¼ˆæ— æ³•å†™å…¥ç¼“å­˜ç›®å½•ï¼‰\n")
            print(f"è§£å†³æ–¹æ¡ˆ:")
            print(f"  â€¢ æ£€æŸ¥ç½‘ç»œè¿æ¥")
            print(f"  â€¢ æ¸…ç†ç£ç›˜ç©ºé—´")
            print(f"  â€¢ ç¡®ä¿å·²é…ç½®é•œåƒ: .\setup_china.ps1\n")
            return False
    
    def translate(
        self, 
        texts: List[str], 
        source_lang: str = "zh", 
        target_lang: str = "en",
        batch_size: int = 8
    ) -> List[str]:
        """
        ç¿»è¯‘æ–‡æœ¬åˆ—è¡¨
        
        Args:
            texts: è¦ç¿»è¯‘çš„æ–‡æœ¬åˆ—è¡¨
            source_lang: æºè¯­è¨€ä»£ç 
            target_lang: ç›®æ ‡è¯­è¨€ä»£ç 
            batch_size: æ‰¹å¤„ç†å¤§å°
            
        Returns:
            List[str]: ç¿»è¯‘åçš„æ–‡æœ¬åˆ—è¡¨
        """
        if not texts:
            return []
        
        # åŠ è½½æ¨¡å‹
        lang_pair = (source_lang, target_lang)
        if not self.load_model(source_lang, target_lang):
            logger.error("æ¨¡å‹åŠ è½½å¤±è´¥")
            return texts  # è¿”å›åŸæ–‡
        
        tokenizer = self.tokenizers[lang_pair]
        model = self.models[lang_pair]
        
        translated_texts = []
        
        try:
            # åˆ†æ‰¹å¤„ç†
            for i in range(0, len(texts), batch_size):
                batch = texts[i:i + batch_size]
                
                # Tokenize
                inputs = tokenizer(
                    batch, 
                    return_tensors="pt", 
                    padding=True, 
                    truncation=True,
                    max_length=512
                ).to(self.device)
                
                # ç”Ÿæˆç¿»è¯‘
                with torch.no_grad():
                    translated = model.generate(**inputs)
                
                # Decode
                batch_translations = tokenizer.batch_decode(
                    translated, 
                    skip_special_tokens=True
                )
                
                translated_texts.extend(batch_translations)
                
                # åªåœ¨æ‰¹é‡ç¿»è¯‘æ—¶æ˜¾ç¤ºè¿›åº¦
                if len(texts) > 3:
                    print(f"  ç¿»è¯‘è¿›åº¦: {len(translated_texts)}/{len(texts)}", end='\r', flush=True)
            
            # æ¸…é™¤è¿›åº¦è¡Œ
            if len(texts) > 3:
                print(" " * 50, end='\r')
            
            return translated_texts
            
        except Exception as e:
            print(f"\nâŒ ç¿»è¯‘å¤±è´¥: {e}")
            return texts  # è¿”å›åŸæ–‡
    
    def translate_single(
        self, 
        text: str, 
        source_lang: str = "zh", 
        target_lang: str = "en"
    ) -> str:
        """
        ç¿»è¯‘å•ä¸ªæ–‡æœ¬
        
        Args:
            text: è¦ç¿»è¯‘çš„æ–‡æœ¬
            source_lang: æºè¯­è¨€ä»£ç 
            target_lang: ç›®æ ‡è¯­è¨€ä»£ç 
            
        Returns:
            str: ç¿»è¯‘åçš„æ–‡æœ¬
        """
        if not text or not text.strip():
            return text
        
        results = self.translate([text], source_lang, target_lang)
        return results[0] if results else text
    
    def detect_language(self, text: str) -> str:
        """
        ç®€å•çš„è¯­è¨€æ£€æµ‹ï¼ˆåŸºäºå­—ç¬¦åˆ¤æ–­ï¼‰
        
        Args:
            text: è¦æ£€æµ‹çš„æ–‡æœ¬
            
        Returns:
            str: è¯­è¨€ä»£ç  ('zh' æˆ– 'en')
        """
        if not text:
            return "en"
        
        # ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦æ•°é‡
        chinese_chars = sum(1 for char in text if '\u4e00' <= char <= '\u9fff')
        total_chars = len(text.strip())
        
        if total_chars == 0:
            return "en"
        
        # å¦‚æœä¸­æ–‡å­—ç¬¦è¶…è¿‡30%ï¼Œåˆ¤å®šä¸ºä¸­æ–‡
        if chinese_chars / total_chars > 0.3:
            return "zh"
        else:
            return "en"
    
    def auto_translate(self, text: str, target_lang: str = None) -> dict:
        """
        è‡ªåŠ¨æ£€æµ‹è¯­è¨€å¹¶ç¿»è¯‘
        
        Args:
            text: è¦ç¿»è¯‘çš„æ–‡æœ¬
            target_lang: ç›®æ ‡è¯­è¨€ï¼ˆå¯é€‰ï¼Œè‡ªåŠ¨åå‘ç¿»è¯‘ï¼‰
            
        Returns:
            dict: åŒ…å«ç¿»è¯‘ç»“æœå’Œå…ƒä¿¡æ¯
        """
        source_lang = self.detect_language(text)
        
        # è‡ªåŠ¨ç¡®å®šç›®æ ‡è¯­è¨€
        if target_lang is None:
            target_lang = "en" if source_lang == "zh" else "zh"
        
        # ç¿»è¯‘
        translated_text = self.translate_single(text, source_lang, target_lang)
        
        return {
            "original_text": text,
            "translated_text": translated_text,
            "source_lang": source_lang,
            "target_lang": target_lang,
            "detected_language": source_lang,
            "language_confidence": 0.95  # ç®€åŒ–ç‰ˆï¼Œå›ºå®šç½®ä¿¡åº¦
        }


# å…¨å±€ç¿»è¯‘å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
_translator_instance = None


def get_translator() -> LocalTranslator:
    """
    è·å–ç¿»è¯‘å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
    
    Returns:
        LocalTranslator: ç¿»è¯‘å™¨å®ä¾‹
    """
    global _translator_instance
    if _translator_instance is None:
        _translator_instance = LocalTranslator()
    return _translator_instance


# ä¾¿æ·å‡½æ•°
def translate_text(
    text: str, 
    source_lang: str = "zh", 
    target_lang: str = "en"
) -> str:
    """
    ç¿»è¯‘å•ä¸ªæ–‡æœ¬çš„ä¾¿æ·å‡½æ•°
    
    Args:
        text: è¦ç¿»è¯‘çš„æ–‡æœ¬
        source_lang: æºè¯­è¨€ä»£ç 
        target_lang: ç›®æ ‡è¯­è¨€ä»£ç 
        
    Returns:
        str: ç¿»è¯‘åçš„æ–‡æœ¬
    """
    translator = get_translator()
    return translator.translate_single(text, source_lang, target_lang)


def translate_texts(
    texts: List[str], 
    source_lang: str = "zh", 
    target_lang: str = "en"
) -> List[str]:
    """
    ç¿»è¯‘å¤šä¸ªæ–‡æœ¬çš„ä¾¿æ·å‡½æ•°
    
    Args:
        texts: è¦ç¿»è¯‘çš„æ–‡æœ¬åˆ—è¡¨
        source_lang: æºè¯­è¨€ä»£ç 
        target_lang: ç›®æ ‡è¯­è¨€ä»£ç 
        
    Returns:
        List[str]: ç¿»è¯‘åçš„æ–‡æœ¬åˆ—è¡¨
    """
    translator = get_translator()
    return translator.translate(texts, source_lang, target_lang)


def auto_translate(text: str, target_lang: str = None) -> dict:
    """
    è‡ªåŠ¨æ£€æµ‹è¯­è¨€å¹¶ç¿»è¯‘çš„ä¾¿æ·å‡½æ•°
    
    Args:
        text: è¦ç¿»è¯‘çš„æ–‡æœ¬
        target_lang: ç›®æ ‡è¯­è¨€ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        dict: ç¿»è¯‘ç»“æœ
    """
    translator = get_translator()
    return translator.auto_translate(text, target_lang)
